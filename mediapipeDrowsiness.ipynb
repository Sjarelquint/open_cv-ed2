{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ed3504-7068-4e01-86fb-43cf3dfabd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a672d16f-a0e2-4fe0-adde-22d1bec42ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70eabaa7-cc35-48f6-ac8e-011669e3bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebacd90-d2c0-460f-a8f4-7531dca47731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('face_landmarker_v2_with_blendshapes.task',\n",
       " <http.client.HTTPMessage at 0x1bbf99b5c40>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task'\n",
    "filename = 'face_landmarker_v2_with_blendshapes.task'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451d7f80-0af9-449a-8c0e-194ff62dbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  face_landmarks_list = detection_result.face_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected faces to visualize.\n",
    "  for idx in range(len(face_landmarks_list)):\n",
    "    face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "    # Draw the face landmarks.\n",
    "    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    face_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "    ])\n",
    "\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp.solutions.drawing_styles\n",
    "        .get_default_face_mesh_tesselation_style())\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp.solutions.drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp.solutions.drawing_styles\n",
    "          .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "  return annotated_image\n",
    "\n",
    "def plot_face_blendshapes_bar_graph(face_blendshapes):\n",
    "  # Extract the face blendshapes category names and scores.\n",
    "  face_blendshapes_names = [face_blendshapes_category.category_name for face_blendshapes_category in face_blendshapes]\n",
    "  face_blendshapes_scores = [face_blendshapes_category.score for face_blendshapes_category in face_blendshapes]\n",
    "  # The blendshapes are ordered in decreasing score value.\n",
    "  face_blendshapes_ranks = range(len(face_blendshapes_names))\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(12, 12))\n",
    "  bar = ax.barh(face_blendshapes_ranks, face_blendshapes_scores, label=[str(x) for x in face_blendshapes_ranks])\n",
    "  ax.set_yticks(face_blendshapes_ranks, face_blendshapes_names)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "  # Label each bar with values\n",
    "  for score, patch in zip(face_blendshapes_scores, bar.patches):\n",
    "    plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{score:.4f}\", va=\"top\")\n",
    "\n",
    "  ax.set_xlabel('Score')\n",
    "  ax.set_title(\"Face Blendshapes\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "730f5ca5-4db9-4bc6-9829-759680fdca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"frame2.jpg\",1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fffe40a-4298-41f1-95ff-249681fe3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb55beb-5a81-4d2e-a27b-bea599fb0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(\"frame2.jpg\")\n",
    "\n",
    "# STEP 4: Detect face landmarks from the input image.\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "# STEP 5: Process the detection result. In this case, visualize it.\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "cv2.imshow('image',annotated_image,)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a86c6a4-96e8-4550-9919-592177275f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mediapipe.python._framework_bindings.image.Image at 0x1bbfa9c7bd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb756f46-d7a5-422c-a290-7d0a2eb20f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a1b604-ede0-4f3d-8381-26e986630bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame) \n",
    "    detection_result = detector.detect(mp_image)\n",
    "    annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), detection_result)\n",
    "    cv2.imshow('Raw Webcam Feed', annotated_image)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12abbdaf-4bc7-4830-b72f-eb37172239fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['face_landmarks', 'face_blendshapes', 'facial_transformation_matrixes'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_result.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c60d868a-d54b-4646-b4d1-96a6d07a723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizedLandmark(x=0.6950324773788452, y=0.20794585347175598, z=0.043302372097969055, visibility=0.0, presence=0.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detection_result.face_landmarks[0])\n",
    "detection_result.face_landmarks[0] [477]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ca5a5-4ca2-4f11-8461-670aaa252a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id,lm in enumerate(detection_result.face_landmarks[0]):\n",
    "    x, y,z,v= int(lm.x * iw), int(lm.y * ih),lm.z,lm.visibility\n",
    "    face_row=[x, y,z,v]\n",
    "    print(face_row)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b2915-b2a3-4cf0-b026-76cac63d2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in detection_result.face_landmarks[0]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c1e9ed-cbc6-405a-a76a-263fe1a16a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046e7ee4-4891-4774-bcf4-3e484248d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 478+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c52fb1-0361-4da2-901f-1c488e446aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coord.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e1ab19-6992-4430-b5b8-2df9d3941f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=\"alert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110ca507-7783-46a7-bd50-eb16f1e2d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame) \n",
    "    detection_result = detector.detect(mp_image)\n",
    "    annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), detection_result)\n",
    "    try:\n",
    "        face=detection_result.face_landmarks[0]\n",
    "        points = list(np.array([[landmark.x, landmark.y, landmark.z,] for landmark in face]).flatten())\n",
    "\n",
    "        # Append class name\n",
    "        points.insert(0, class_name)\n",
    "\n",
    "        # Export to CSV\n",
    "        with open('coord.csv', mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(points)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    cv2.imshow('Raw Webcam Feed', annotated_image)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c7887d5e-49ea-474f-bfbd-a2bf7bf374b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face=detection_result.face_landmarks[0]\n",
    "\n",
    "points = list(np.array([[landmark.x, landmark.y, landmark.z,] for landmark in face]).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54accc-48fa-4565-b0ff-594272959d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350457d7-03f4-484d-ad92-64fcc9b2ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('coord.csv')\n",
    "X = df.drop('class', axis=1).values # features\n",
    "y = df['class'] # target value\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b9b97-cfd9-4d06-b063-b4f0a24f7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28a13c3-2428-42b0-9f2a-38fdbcc3f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}\n",
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea27fb29-036d-4af9-8e71-17cca9ed42c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0 1.0 1.0\n",
      "rc 1.0 1.0 1.0\n",
      "rf 1.0 1.0 1.0\n",
      "gb 0.9775280898876404 0.967741935483871 0.989010989010989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score # Accuracy metrics \n",
    "import pickle \n",
    "for algorithm, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algorithm, accuracy_score(y_test, yhat),\n",
    "          recall_score(y_test, yhat,average='binary',pos_label='drowsy'),\n",
    "          precision_score(y_test, yhat,average='binary',pos_label='drowsy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adcdc5be-7471-451c-8c15-941b4df6c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('drowsiness.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8afa26f6-c488-4ff9-961b-0a04e3e70417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('drowsiness.pkl', 'rb') as f:\n",
    "    model1= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "134ec0ff-55ac-4f30-b94c-5463f4fa6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame) \n",
    "    detection_result = detector.detect(mp_image)\n",
    "    annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), detection_result)\n",
    "    try:\n",
    "        face=detection_result.face_landmarks[0]\n",
    "        points = list(np.array([[landmark.x, landmark.y, landmark.z,] for landmark in face]).flatten())\n",
    "        X = pd.DataFrame([points])\n",
    "        cl = model1.predict(X)[0]\n",
    "        prob = model1.predict_proba(X)[0]\n",
    "        cv2.putText(annotated_image, cl, (50,50), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(annotated_image, str(round(prob[np.argmax(prob)],2)), (100,100), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA) \n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    cv2.imshow('Raw Webcam Feed', annotated_image)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b7275ad-4c6c-45af-89c8-74f7325eea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process(image_path):    \n",
    "    base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "    options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                           output_face_blendshapes=True,\n",
    "                                           output_facial_transformation_matrixes=True,\n",
    "                                           num_faces=1)\n",
    "    detector = vision.FaceLandmarker.create_from_options(options)\n",
    "    cap = cv2.VideoCapture(image_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame=frame.copy()\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame) \n",
    "            detection_result = detector.detect(mp_image)\n",
    "            annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), detection_result)\n",
    "            face=detection_result.face_landmarks[0]\n",
    "            points = list(np.array([[landmark.x, landmark.y, landmark.z,] for landmark in face]).flatten())\n",
    "            X = pd.DataFrame([points])\n",
    "            cl = model1.predict(X)[0]\n",
    "            prob = model1.predict_proba(X)[0]\n",
    "            cv2.putText(annotated_image, cl, (50,50), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, str(round(prob[np.argmax(prob)],2)), (100,100), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            yield annotated_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f3144a-449b-4546-b2df-52a5f2d136b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd08984-16bc-4de2-9953-8265c76167fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "w=cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "h=cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "record=cv2.VideoWriter('output2.mp4',cv2.VideoWriter_fourcc('D','I','V','X'),20,(int(w),int(h)))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    record.write(frame)\n",
    "    cv2.imshow('Raw Webcam Feed', frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "record.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f56012-ff28-411c-a265-6eac2af585f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interface_video = gr.Interface(\n",
    "    fn=process,\n",
    "    inputs=gr.Video(),\n",
    "    outputs=gr.Image(),\n",
    "    title=\"drowsiness detector\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64cd4f-55db-4bc3-aaf2-c758873f5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface_video.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c29bf46-4b5d-4d3d-a44f-f187f3c925c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process2(img):\n",
    "    cap=cv2.VideoCapture(img)\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        if ret:\n",
    "            return cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "# cap.release()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d0406-24a3-4fbe-aec2-481fe148c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Convert the frame to grayscale\n",
    "    cap=cv2.VideoCapture(frame)\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        if ret:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply a Gaussian blur to the frame\n",
    "            blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "            # Detect edges in the frame using the Canny algorithm\n",
    "            edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "            yield edges\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(fn=process_frame, inputs=\"video\", outputs=\"image\")\n",
    "\n",
    "# Launch the interface\n",
    "iface.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32112191-cbcd-44de-b1b0-74aea83e89d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
