{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e3c18f-8ba7-437f-a5ef-3c59396a6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab8ba3e-fff3-4749-aaf0-c6c883eb2aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_pose = mp.solutions.pose # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37091c40-a5cc-44ae-9bd2-a1a7d549d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(static_image_mode=False,\n",
    "                          model_complexity=1,\n",
    "                          smooth_landmarks=True,\n",
    "                          enable_segmentation=False,\n",
    "                          smooth_segmentation=True,\n",
    "                          min_detection_confidence=0.5,\n",
    "                          min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    " # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f64dbd6-785a-47f2-a155-ba096c230920",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "videowriter = cv2.VideoWriter('deadlift.avi', fourcc, fps, (int(w),int(h)))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    videowriter.write(frame)\n",
    "    cv2.imshow('video feed', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "videowriter.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "294c58a1-2553-44dc-b2be-d67be210d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "videowriter.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6c99e2-fd78-46b3-8559-642904d5dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc1832e-6942-4ce4-aff4-cc9ea4cca13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ab80ac-5cc2-4b26-80b2-c20caec99cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('points.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02ebb8e7-77ce-48aa-adb0-4bff7004c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmarks(results,action):        \n",
    "    try:\n",
    "        # Extract Pose landmarks\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        points = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        # Append class name\n",
    "        points.insert(0, action)\n",
    "\n",
    "        # Export to CSV\n",
    "        with open('points.csv', mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(points)\n",
    "\n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a049aa4e-2b2a-4141-9314-1447aad8938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(static_image_mode=False,\n",
    "                          model_complexity=1,\n",
    "                          smooth_landmarks=True,\n",
    "                          enable_segmentation=False,\n",
    "                          smooth_segmentation=True,\n",
    "                          min_detection_confidence=0.5,\n",
    "                          min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    " # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        k=cv2.waitKey(1)\n",
    "        if k==97:\n",
    "            export_landmarks(results,'up')\n",
    "        if k==122:\n",
    "            export_landmarks(results,'down')\n",
    "            \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c71cef9-4890-4734-95ae-8a912e2e2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8ce373-3348-4acb-a749-393bc28140b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('points.csv')\n",
    "X = df.drop('class', axis=1).values # features\n",
    "y = df['class'] # target value\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952d7c86-e442-46c9-86c4-0e55d73506f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}\n",
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7b59c4-68a9-42af-a2c1-1299712a4a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.8333333333333334 1.0 0.75\n",
      "rc 1.0 1.0 1.0\n",
      "rf 1.0 1.0 1.0\n",
      "gb 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score,precision_score # Accuracy metrics \n",
    "import pickle \n",
    "for algorithm, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algorithm, accuracy_score(y_test, yhat),\n",
    "          recall_score(y_test, yhat,average='binary',pos_label='up'),\n",
    "          precision_score(y_test, yhat,average='binary',pos_label='up'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9615dd91-1e99-4fbe-b6e3-8b3946da0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deadlift.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d074d045-99d5-445f-98f6-20ada8d49f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deadlift.pkl', 'rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d3b7592-69de-43b9-b78e-d8d48a8467e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2262590218.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\azpow\\AppData\\Local\\Temp\\ipykernel_1996\\2262590218.py\"\u001b[1;36m, line \u001b[1;32m42\u001b[0m\n\u001b[1;33m    elif  current_state='down' and body_language_class=='up' and body_language_prob[body_language_prob.argmax()]>.5:\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "counter=0\n",
    "with mp_pose.Pose(static_image_mode=False,\n",
    "                          model_complexity=1,\n",
    "                          smooth_landmarks=True,\n",
    "                          enable_segmentation=False,\n",
    "                          smooth_segmentation=True,\n",
    "                          min_detection_confidence=0.5,\n",
    "                          min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    " # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose_raw = results.pose_landmarks.landmark\n",
    "            points = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose_raw]).flatten())\n",
    "            X = pd.DataFrame([points])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            cv2.putText(image, body_language_class, (50,50), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2)), (100,100), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)    \n",
    "            cv2.imshow('Raw Webcam Feed', image)\n",
    "            if body_language_class=='down' and body_language_prob[body_language_prob.argmax()]>.5:\n",
    "                current_state='down'\n",
    "            elif  current_state='down' and body_language_class=='up' and body_language_prob[body_language_prob.argmax()]>.5:\n",
    "                current_state='up'\n",
    "                counter+=1\n",
    "            cv2.putText(image, str(counter), (150,150), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "\n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb38d7c-8ea5-4f41-a0d4-b65e376adaef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
